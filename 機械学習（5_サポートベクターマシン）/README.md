# Study-AI 実装演習レポート

## 機械学習（サポートベクタ―マシン）

### 1. 要点まとめ

サポートベクタマシン（SVM）は、もともとは 2クラス分類問題のために開発された、教師あり学習での分類手法である。その後、回帰問題や教師なし問題へも応用されている。

|キーワード|概要|
|---|---|
|決定関数|2クラス分類の際、どちらのクラスに属するか判定するための関数。|
|分類境界|２つのクラスを分ける境界線。|
|訓練データ|特徴ベクトルとラベルのセット。|
|マージン|分類境界を挟んで２つのクラスがどのくらい離れているかを表わすもの。このマージンは大きいほど良い（マージン最大化）|
|制約条件|複数の条件を同時に満たすことを要求するもの。<br>①分類境界から最も近いベクトルを選び、②それらの距離を最大化する。|
|ハードマージン|分離可能性（訓練データを完璧に分類できる）を仮定したSV分類。|
|ソフトマージン|多少の誤りは許すように分類する。|
|サポートベクトル|分類境界に最も近いデータ。|
|スラック変数|マージンに対する許容誤差。|
|正則化係数(C)|過学習を防ぐ目的で使用されるハイパーパラメータ。Cが大きいほどハードマージンに近づき誤分類が少ない。Cが小さいほと誤分類が許容される。|
|主問題、双対問題|主問題に比べて双対問題は変数を少なくできる。分類境界の非線形化を考える上で双対形式の方が有利。|
|勾配|偏微分をまとめたベクトル。|
|ラグランジュ関数|成約条件付きの最適化問題に対する手法。|
|弱双対性、強双対性|主問題と双対問題の最適地に関する性質。|
|写像|高次元データへの拡張。非線形分離のためのアイデア。|
|カーネル関数|内積計算を簡略化するテクニック。|

### 2. 実装演習

- irisデータの分類を演習。
[(sklearnでの実行結果)](Exercises-1.ipynb)

### 3. 考察

明確にターゲットを分離できないな場合は、ソフトマージンでの分類を行う。誤分類の許容程度として正則化係数を加味する必要がある。

### 4. 関連記事

https://python.atelierkobato.com/iris/
https://qiita.com/renesisu727/items/964005bd29aa680ad82d
https://qiita.com/renesisu727/items/3fbed61e3253934eb68e
